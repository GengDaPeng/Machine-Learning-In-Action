{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ***************************************************/ \n",
    "# @Time    : 2018/6/5 14:52\n",
    "# @Author  : GengDaPeng\n",
    "# @contact : bingshan222@hotmail.com\n",
    "# @File    : DecisionTree.py\n",
    "# @Desc    : 《机器学习实战》 决策树构造章节py3代码\n",
    "# ***************************************************/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cerate_dataset():\n",
    "    \"\"\" 创建数据集 \"\"\"\n",
    "    dataset = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataset, labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcShanonEnt(dataset):\n",
    "    \"\"\" 计算香农熵 \"\"\"\n",
    "    num_entries = len(dataset)\n",
    "    label_cunt = {}     # 创建统计标签（label）的字典\n",
    "    for featvec in dataset:\n",
    "        current_label = featvec[-1]\n",
    "        if current_label not in label_cunt.keys():\n",
    "            label_cunt[current_label] = 0   # 如果标签(label)不存在，则创建新标签并设值为0\n",
    "        label_cunt[current_label] += 1  # 值加1\n",
    "    shannonent = 0.0    # 信息熵\n",
    "    for key in label_cunt:\n",
    "        prob = float(label_cunt[key]) / num_entries     # 标签概率\n",
    "        shannonent -= prob * np.log2(prob)    # 求以2为底的对数\n",
    "    return shannonent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_dataset(dataset, axis, value):\n",
    "    \"\"\" 按照给定特征划分数据集\n",
    "    Parameters:\n",
    "        dataset - 带划分的数据集\n",
    "        axis - 划分数据集的特征\n",
    "        value - 需要返回的特征值\n",
    "    Returns:\n",
    "        ret_dataset -按照给定特征划分后返回的特征数据集\n",
    "    \"\"\"\n",
    "    ret_dataset = []     # 创建返回的数据集列表\n",
    "    for featvec in dataset:     # 遍历数据集\n",
    "        if featvec[axis] == value:   # 特征是否符合要求\n",
    "            reduce_featvec = featvec[:axis]  # 去除axis特征\n",
    "            reduce_featvec.extend(featvec[axis+1:])   # 提取划分后的特征\n",
    "            ret_dataset.append(reduce_featvec)   # 添加到数据集列表\n",
    "    return ret_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataset):\n",
    "    \"\"\" 选择最好的数据集划分方式\n",
    "    parameter:\n",
    "        dataset - 划分的数据集\n",
    "    return:\n",
    "        bestfrature - 最佳特征\n",
    "    \"\"\"\n",
    "    num_features = len(dataset[0]) - 1\n",
    "    base_entropy = calcShanonEnt(dataset)\n",
    "    bestinfogain = 0.0\n",
    "    bestfeature = -1\n",
    "    for i in range(num_features):\n",
    "        featlist = [example[i] for example in dataset]\n",
    "        uniquevals = set(featlist)\n",
    "        new_entropy = 0.0\n",
    "        for value in uniquevals:\n",
    "            subdataset = split_dataset(dataset, i, value)\n",
    "            prob = len(subdataset) / float(len(dataset))\n",
    "            new_entropy += prob * calcShanonEnt(subdataset)\n",
    "        infogain = base_entropy - new_entropy\n",
    "        if (infogain > bestinfogain):\n",
    "            bestinfogain = infogain\n",
    "            bestfeature = i\n",
    "    return bestfeature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "----------------------\n",
      "0.9709505944546686\n",
      "------------------------\n",
      "[]\n",
      "[[1, 'yes'], [1, 'yes'], [0, 'no']]\n",
      "[[1, 'no'], [1, 'no']]\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    mydat, labels = cerate_dataset()\n",
    "    print(mydat)\n",
    "    print('----------------------')\n",
    "    shan = calcShanonEnt(mydat)\n",
    "    print(shan)\n",
    "    print('------------------------')\n",
    "    ret_dataset1 = split_dataset(mydat, 0, 1)\n",
    "    print(mydat[0][:0])\n",
    "    print(ret_dataset1)\n",
    "    ret_dataset2 = split_dataset(mydat, 0, 0)\n",
    "    print(ret_dataset2)\n",
    "    print('---------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
