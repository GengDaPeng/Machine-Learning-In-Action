{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习实战——决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ***************************************************/ \n",
    "# @Time    : 2018/6/5 14:52\n",
    "# @Author  : GengDaPeng\n",
    "# @contact : bingshan222@hotmail.com\n",
    "# @File    : DecisionTree.py\n",
    "# @Desc    : 《机器学习实战》 决策树构造章节py3代码\n",
    "# ***************************************************/\n",
    "import operator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cerate_dataset():\n",
    "    \"\"\" 创建数据集 \"\"\"\n",
    "    dataset = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcShanonEnt(dataset):\n",
    "    \"\"\" 计算信息熵 \"\"\"\n",
    "    num_entries = len(dataset)\n",
    "    label_cunt = {}     # 创建统计标签（label）的字典\n",
    "    for featvec in dataset:\n",
    "        current_label = featvec[-1]\n",
    "        if current_label not in label_cunt.keys():\n",
    "            label_cunt[current_label] = 0   # 如果标签(label)不存在，则创建新标签并设值为0\n",
    "        label_cunt[current_label] += 1  # 值加1\n",
    "    shannonent = 0.0    # 信息熵\n",
    "    for key in label_cunt:\n",
    "        prob = float(label_cunt[key]) / num_entries     # 标签概率\n",
    "        shannonent -= prob * np.log2(prob)    # 求以2为底的对数\n",
    "    return shannonent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_dataset(dataset, axis, value):\n",
    "    \"\"\" 按照给定特征划分数据集\n",
    "    Parameters:\n",
    "        dataset - 带划分的数据集\n",
    "        axis - 划分数据集的特征\n",
    "        value - 需要返回的特征值\n",
    "    Returns:\n",
    "        ret_dataset -按照给定特征划分后返回的特征数据集\n",
    "    \"\"\"\n",
    "    ret_dataset = []     # 创建返回的数据集列表\n",
    "    for featvec in dataset:     # 遍历数据集\n",
    "        if featvec[axis] == value:   # 特征是否符合要求\n",
    "            reduce_featvec = featvec[:axis]  # 去除axis特征\n",
    "            reduce_featvec.extend(featvec[axis+1:])   # 提取划分后的特征\n",
    "            ret_dataset.append(reduce_featvec)   # 添加到数据集列表\n",
    "    return ret_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataset):\n",
    "    \"\"\" 选择最好的数据集划分方式\n",
    "    parameter:\n",
    "        dataset - 划分的数据集\n",
    "    return:\n",
    "        bestfrature - 最佳特征\n",
    "    \"\"\"\n",
    "    num_features = len(dataset[0]) - 1\n",
    "    base_entropy = calcShanonEnt(dataset)   # 计算数据集最初的信息熵\n",
    "    bestinfogain = 0.0\n",
    "    bestfeature = -1\n",
    "    for i in range(num_features):    # 遍历数据集中所有的特征\n",
    "        featlist = [example[i] for example in dataset]     \n",
    "        uniquevals = set(featlist)     # 创建集合，得到唯一元素值\n",
    "        new_entropy = 0.0\n",
    "        for value in uniquevals:\n",
    "            subdataset = split_dataset(dataset, i, value)      # 怎对每一个特征划分数据集\n",
    "            prob = len(subdataset) / float(len(dataset))\n",
    "            new_entropy += prob * calcShanonEnt(subdataset)      # 计算信息熵\n",
    "        infogain = base_entropy - new_entropy\n",
    "        if (infogain > bestinfogain):\n",
    "            bestinfogain = infogain\n",
    "            bestfeature = i\n",
    "    return bestfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityCnt(classlist):\n",
    "    class_count={}\n",
    "    for vote in classlist:\n",
    "        if vote not in class_count.keys():\n",
    "            class_count[vote] = 0\n",
    "        class_count[vote] += 1\n",
    "    sorted_class_count = sorted(class_count.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_class_count[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mf:\\anaconda3\\lib\\site-packages\\ipython\\core\\compilerop.py\u001b[0m(99)\u001b[0;36mast_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     97 \u001b[1;33m        \u001b[0mArguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mexactly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     98 \u001b[1;33m        and are passed to the built-in compile function.\"\"\"\n",
      "\u001b[0m\u001b[1;32m---> 99 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    100 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    101 \u001b[1;33m    \u001b[1;32mdef\u001b[0m \u001b[0mreset_compiler_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "ipdb> c\n",
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "----------------------\n",
      "0.9709505944546686\n",
      "------------------------\n",
      "[]\n",
      "[[1, 'yes'], [1, 'yes'], [0, 'no']]\n",
      "[[1, 'no'], [1, 'no']]\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    mydat, labels = cerate_dataset()\n",
    "    print(mydat)\n",
    "    print('----------------------')\n",
    "    shan = calcShanonEnt(mydat)\n",
    "    print(shan)\n",
    "    print('------------------------')\n",
    "    ret_dataset1 = split_dataset(mydat, 0, 1)\n",
    "    print(mydat[0][:0])\n",
    "    print(ret_dataset1)\n",
    "    ret_dataset2 = split_dataset(mydat, 0, 0)\n",
    "    print(ret_dataset2)\n",
    "    print('---------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
